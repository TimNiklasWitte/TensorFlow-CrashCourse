{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c09f58a0",
   "metadata": {},
   "source": [
    "# TensorFlow Crash Course\n",
    "# Part 3 Exercises\n",
    "\n",
    "\n",
    "## 1. Colorize Tim's Garden\n",
    "\n",
    "In this task, you will first remove the color from this picture:\n",
    "<img src=\"task_1/Garden.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "Thereafter, you will colorize this image by passing it through a convolutional autoencoder. This neural network was trained on the [ImageNet2012 dataset](https://www.tensorflow.org/datasets/catalog/imagenet2012) to colorize gray images.\n",
    "\n",
    "All files for solving this task are in the folder `task_1`.\n",
    "\n",
    "### 1.1 Model setup\n",
    "In the folder `task_1` you can find the `Autoencoder.py` file. It contains the class definition of the `Autoencoder` class. First, create an `Autoencoder` object.\n",
    "Now you build the model - call the `build` method. Note that, its input shape is `(1, 256, 256, 1)`. In other words, the batch size is `1`. The image has a size of `256x256` pixels and the `1` represents the amount of color channels. There is only one color channel - gray ;).\n",
    "Thereafter, you will load its trained weights from the `trainied_weights_epoch_12` file.\n",
    "How many parameters has the model? You can use the `summary` method to get the answer.\n",
    "\n",
    "### 1.2 Preprocessing\n",
    "The image `img` is already loaded from the file `Garden.jpg`. It is required that the image has the size of 256x256 pixels. Therefore, you must resize it. In the following, we want to remove the color from the image. You can gray scale an image by taking the average RGB value for each pixel.\n",
    "The `gray_img` tensor shall have now the shape `(256, 256)`. Due to passing it through convolution layers, a channel dimension is required. \n",
    "As a consequence, it must have the shape `(256, 256, 1)`.\n",
    "Moreover, a batch dimension is expected. Overall, `gray_img` must have the shape `(1, 256, 256, 1)`. Besides, the `autoencoder` expects its input to be in the range of `[-1, 1]`: Normalize the input this way! Before you can do this: Convert the `gray_img` tensor into `float32`.\n",
    "\n",
    "### 1.3 Inference\n",
    "Now, you can pass the `gray_img` tensor through the `autoencoder` in order to get `ab_values`.\n",
    "Next, you must remove the batch dimension. Note that, the `ab_values` are **not** RGB values. For optimization purposes, the `autoencoder` returns A and B values from the [LAB (aka) Color space](https://www.xrite.com/-/media/modules/weblog/blog/lab-color-space/lab-color-space.png?h=622&w=600&la=de&hash=CE9206A0BC3F787A0167DED17D316539ED0C5C08). By concatenating the gray color channels with the A and B color channels (model output), the colorized image is reconstructed. Due to a complex rescaling is applied before the CLAB image is converted into a RGB image, this job is done already for you by the `getRGB` function. Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb88f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./task_1\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from Autoencoder import Autoencoder\n",
    "import tensorflow_io as tfio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25a56426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRGB(L, AB, batch_mode=True):\n",
    "    # Remove normalization\n",
    "    L = (L + 1)*50\n",
    "    AB = ((AB - 1)*255/2)+128\n",
    "\n",
    "    if batch_mode:\n",
    "        L = tf.reshape(L, (32, 256,256,1))\n",
    "        LAB = tf.concat([L, AB], 3)\n",
    "    else:\n",
    "        L = tf.reshape(L, (256,256,1))\n",
    "        LAB = tf.concat([L, AB], 2)\n",
    "    rgb = tfio.experimental.color.lab_to_rgb(LAB)\n",
    "\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e45f90ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Model setup\n",
    "# create an autoencoder object\n",
    "\n",
    "# build the model\n",
    "\n",
    "# load weights\n",
    "\n",
    "# Hint: the adam optimizer was used - it's learning rates are not stored \n",
    "# -> suppress warnings: use .expect_partial() while loading weights\n",
    "\n",
    "# call summary on the object\n",
    "\n",
    "\n",
    "# 1.2 Preprocessing\n",
    "# Load the image\n",
    "img = plt.imread(\"./task_1/Garden.jpg\")\n",
    "# Resize it into the size of 256x256. Use cv2 for this!\n",
    "\n",
    "# Plot it!\n",
    "#plt.title(\"Ground Truth\")\n",
    "#plt.imshow(img)\n",
    "#plt.axis(\"off\")\n",
    "#plt.show()\n",
    "\n",
    "# Remove the colors (average over all RGB values of a pixel)\n",
    "#gray_img = \n",
    "# gray_img.shape = (256,256)\n",
    "\n",
    "# Plot it!\n",
    "#plt.title(\"Gray\")\n",
    "#plt.imshow(gray_img, cmap=\"gray\")\n",
    "#plt.axis(\"off\")\n",
    "#plt.show()\n",
    "\n",
    "# Add color channel (gray)\n",
    "\n",
    "# gray_img.shape = (256, 256, 1)\n",
    "\n",
    "# Add batch dim\n",
    "\n",
    "# gray_img.shape = (1, 256, 256, 1)\n",
    "\n",
    "\n",
    "# Cast to tf.float32 by using tf.cast\n",
    "\n",
    "# Normalization: [0,255] -> [-1, 1]\n",
    "\n",
    "# 1.3 Inference\n",
    "# Pass gray_img to the autoencoder\n",
    "#ab_img = \n",
    "\n",
    "# Remove batch dim\n",
    "#rgb_img = getRGB(gray_img, ab_img, batch_mode=False) # uncomment me!\n",
    "\n",
    "\n",
    "#plt.title(\"Colorized\")\n",
    "#plt.imshow(rgb_img)\n",
    "#plt.axis(\"off\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa8ed6",
   "metadata": {},
   "source": [
    "## 2. Pairwise Concatenation\n",
    "\n",
    "The tensor `x` represents a sequence of the following three elements: `[1,2,3]`, `[4,5,6]`, `[7,8,9]`.\n",
    "<code>\n",
    "tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
    "array([[1, 2, 3],\n",
    "       [4, 5, 6],\n",
    "       [7, 8, 9]], dtype=int32)\n",
    "</code>\n",
    "\n",
    "Each element of the sequence shall be concatenated with each other - including with itself.\n",
    "The result is the following tensor:\n",
    "<code>\n",
    "tf.Tensor: shape=(9, 6), dtype=int32, numpy=\n",
    "array([[1, 2, 3, 1, 2, 3],\n",
    "       [1, 2, 3, 4, 5, 6],\n",
    "       [1, 2, 3, 7, 8, 9],\n",
    "       [4, 5, 6, 1, 2, 3],\n",
    "       [4, 5, 6, 4, 5, 6],\n",
    "       [4, 5, 6, 7, 8, 9],\n",
    "       [7, 8, 9, 1, 2, 3],\n",
    "       [7, 8, 9, 4, 5, 6],\n",
    "       [7, 8, 9, 7, 8, 9]], dtype=int32\n",
    "</code>\n",
    "\n",
    "Write code that performs this operation with `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d6f807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
    "seq_len = x.shape[0]\n",
    "input_dim = x.shape[1]\n",
    "\n",
    "# Hint: tile, concat and transpose is all you need ;)\n",
    "# ... and a reshape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d9aefc",
   "metadata": {},
   "source": [
    "## 3. Tensor Broadcasting \n",
    "\n",
    "Let `a` be a tensor with a shape of `(1,2,3)`.\n",
    "\n",
    "Let `b` be a tensor with a shape of `(3,3)`.\n",
    "\n",
    "Explain why the operation `a+b` can not be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ede0a3",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
